## Reinforcement Learning

Intelligence -> **goal-directed** adaptive behavior

Intelligence in Reinforcement Learning: *Learning to make decisions to achieve goals* 

An intelligent agent interacts with the **environment** by perceive an observation and take an action accordingly which leads to a **reward**.

Our goal is **maximizing** the sum of the rewards in the future.

### Reward hypothesis

Any goal can be formalized as the outcome of maximizing a cumulative reward.
Ideally we can formalize any problem as a reinforcement learning problem.

**Reward is enough**: intelligence, and its associated abilities, can be understood as subserving the maximization of reward by an agent acting in its environment.